# Kaggle diamond competition
---
![portada](images/Machine-learning-860x573.jpg)
---
# IntroducciÃ³n
En [Ironhack](https://www.ironhack.com/) han realizado una pequeÃ±a competiciÃ³n en [Kaggle](https://www.kaggle.com/competitions/diamonds-datamad1022/overview) de machine learning, donde todos los alumnos compiten por conseguir el mejor modelo predictivo de los precios de los diamantes en base a sus caracterÃ­sticas. ğŸ’ğŸ’

Obviamente la competiciÃ³n es abierta, por lo que no solo estÃ¡ limitado a los alumnos de Ironhack.

Ya hicimos un par de modelos anteriormente en el modelo, por que ademÃ¡s quise ponerme un pequeÃ±o reto, que consiste en intentar automatizar mucho mÃ¡s este proceso mediante un buen pipeline. ğŸ’ªğŸ’ª

---
# Objetivos

- Realizar un buen EDA, donde se estudiarÃ¡ la naturaleza de nuestros datos, gestiÃ³n de nulos y gestiÃ³n de ouliers. ğŸ“Š
- Preparar los datos para nuestro modelo, realizando normalizaciÃ³n, estandarizaciÃ³n y encoding si fuese necesario. ğŸ“‰
- Entrenar diversos modelos y analizar sus mÃ©tricas, quedÃ¡ndonos con el modelo que se ajuste mÃ¡s a nuestras preferencias. ğŸ’»
- Crear un pipeline o archivo soporte que me sirva para futuros modelos predictivos. ğŸ§‘â€ğŸ”§
- Y por Ãºltimo y no menos importante... Â¡Ganar!ğŸ†
---
# Pipeline

- El pipeline estÃ¡ compuesto de diversas funciones, donde en el futuro irÃ© aÃ±adiendo mÃ¡s.

- Estas funciones en un futuro planeo juntarlas en una clase, para que haya mÃ¡s interactividad entre funciones.

- Las funciones son un poco complejas al principio, por lo que recomiendo leer bien su domunetaciÃ³n [aquÃ­](https://github.com/XiangLinZ/Kaggle_diamond_competition/blob/main/src/soporte.py). ğŸ‘ˆğŸ‘ˆ


---
# Proceso
![portada2](images/diamantes_colores.jfif)

### Este proyecto tiene como objetivo predecir el precio de diamantes a partir de caracterÃ­sticas como el peso, la claridad, el color y el corte. A continuaciÃ³n, se detallan los pasos seguidos en este proyecto:

- Entendimiento del problema: Se analizÃ³ la competencia de Kaggle y se estudiÃ³ la naturaleza del problema. Se identificÃ³ que se trata de un problema de regresiÃ³n, ya que lo que queremos predecir es el precio.ğŸ’°ğŸ’°

- ExploraciÃ³n de los datos: Se analizaron las caracterÃ­sticas de los datos y se estudiÃ³ la distribuciÃ³n de las variables. Se identificaron posibles relaciones entre las variables y se buscaron posibles outliers.ğŸ˜¯ğŸ˜¯
![outliers](images/outliers.png)
En mi caso, hay bastantes datos agrupados cerca del Q3 y decidÃ­ quedarme esos datos.

- Preprocesamiento de los datos: Se realizaron diversas tÃ©cnicas de preprocesamiento para preparar los datos para su uso en modelos de aprendizaje automÃ¡tico. Entre ellas se incluyen la eliminaciÃ³n de valores nulos, la codificaciÃ³n de variables categÃ³ricas y la normalizaciÃ³n de las variables numÃ©ricas. Como enfoque, los nulos se han tratado mediante un proceso de Iterative Imputer, que el que se comparan los datos con el resto, para darles un valor semejante.

- SelecciÃ³n de modelos: Se seleccionaron varios modelos de regresiÃ³n, entre ellos Decision Tree Regressor, Random Forest Regressor, Gradient Boosting Regressor y K-Nearest Neighbors Regressor. ğŸ¤”ğŸ¤”

- Mejora de los modelos: Se aplicaron tÃ©cnicas de mejora de modelos, como la validaciÃ³n cruzada y el ajuste de hiperparÃ¡metros. Se compararon los modelos y se seleccionÃ³ el mejor. ğŸ‘ğŸ‘

- Entrenamiento y validaciÃ³n: Se entrenÃ³ varios modelos y se validÃ³ con un conjunto de datos de prueba. Se evaluÃ³ el rendimiento del modelo con las mÃ©tricas de los diversos modelos. ğŸ“ŠğŸ“Š

- Predicciones: Se usÃ³ el modelo para hacer predicciones en un conjunto de datos desconocido y se guardÃ³ el resultado en un archivo CSV, que posteriormente se subiÃ³ a la competiciÃ³n de [Kaggle](https://www.kaggle.com/competitions/diamonds-datamad1022/overview).

---
# Mejor modelo
![portada3](images/modelos-predictivos.jpg)

Las mÃ©tricas de mi mejor modelo son:
- MSE:
- RMSE:
- R2:

CaracterÃ­sticas especiales del modelo:
- Variables conservadas:
- GestiÃ³n de outliers:
- EstandarizaciÃ³n:
- Modelo:
- MÃ©tricas del modelo:
---
# Herramientas
### He usado diversas herramientas en este proyecto con distintos fines, aquÃ­ enumero las herramientas, junto a una pequeÃ±a descripciÃ³n de estas.

- [Numpy](https://numpy.org/): Es una biblioteca de Python para trabajar con matrices y arreglos multidimensionales.
- [Pandas](https://pandas.pydata.org/): Es una biblioteca de software libre para el lenguaje de programaciÃ³n Python destinada a manipulaciÃ³n y anÃ¡lisis de datos.

- [Matplotlib](https://matplotlib.org/): Es una biblioteca de Python para la generaciÃ³n de grÃ¡ficos y visualizaciones.

- [Seaborn](https://seaborn.pydata.org/): Biblioteca de Python para la visualizaciÃ³n de datos basada en matplotlib.

- [Random](https://docs.python.org/3/library/random.html): Una biblioteca de Python que permite trabajar con nÃºmeros aleatorios.

- [Pickle](https://docs.python.org/3/library/pickle.html): Biblioteca de Python que permite serializar y deserializar objetos de Python.

- [Tqdm](https://github.com/tqdm/tqdm): Es una biblioteca de Python para mostrar una barra de progreso en bucles y operaciones iterables.

- [Scikit-learn (sklearn)](https://scikit-learn.org/stable/) es una biblioteca de aprendizaje automÃ¡tico de cÃ³digo abierto para Python. Proporciona herramientas simples y eficientes para la minerÃ­a y anÃ¡lisis de datos, asÃ­ como para la construcciÃ³n de modelos de aprendizaje automÃ¡tico y la evaluaciÃ³n de su rendimiento.